{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 20:38:25.877505: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-10 20:38:25.906654: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-10 20:38:26.560777: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] DJI     : 161 files (drone)\n",
      "[INFO] PHANTOM : 254 files (drone)\n",
      "[INFO] NOISE   : 657 files (no-drone)\n",
      "[INFO] TOTAL   : 1072 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757518707.437491   10123 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 890 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0000 00:00:1757518707.438638   10123 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21759 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:05:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluating model: /home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_orignal.keras  (threshold=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 20:38:28.252397: I external/local_xla/xla/service/service.cc:163] XLA service 0x764ea800dbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-10 20:38:28.252419: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-10 20:38:28.252423: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-10 20:38:28.262375: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-10 20:38:28.330825: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-09-10 20:38:28.341238: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-10 20:38:28.668972: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_235', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-09-10 20:38:28.835723: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-10 20:38:28.940949: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757518709.243229   10960 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-09-10 20:38:29.397824: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-10 20:38:29.545775: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_235', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-09-10 20:38:29.773796: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_235', 576 bytes spill stores, 576 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 837ms/step\n",
      "[OVERALL] N=1072\n",
      "  Acc    : 0.8815\n",
      "  AUROC  : 0.9576\n",
      "  AUPRC  : 0.9380\n",
      "  F1     : 0.8515\n",
      "\n",
      "================================================================================\n",
      "Evaluating model: /home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_data_01.keras  (threshold=0.35)\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step\n",
      "[OVERALL] N=1072\n",
      "  Acc    : 0.8060\n",
      "  AUROC  : 0.9589\n",
      "  AUPRC  : 0.9311\n",
      "  F1     : 0.7973\n",
      "\n",
      "================================================================================\n",
      "Evaluating model: /home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_data_02.keras  (threshold=0.35)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7650941b1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 519ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7650941b1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step\n",
      "[OVERALL] N=1072\n",
      "  Acc    : 0.7435\n",
      "  AUROC  : 0.9770\n",
      "  AUPRC  : 0.9682\n",
      "  F1     : 0.7502\n",
      "\n",
      "================================================================================\n",
      "Evaluating model: /home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_smoothing_AdamW.keras  (threshold=0.4)\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step\n",
      "[OVERALL] N=1072\n",
      "  Acc    : 0.8284\n",
      "  AUROC  : 0.9904\n",
      "  AUPRC  : 0.9854\n",
      "  F1     : 0.8182\n",
      "\n",
      "================================================================================\n",
      "Evaluating model: /home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_SE_Aug.keras  (threshold=0.3)\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723ms/step\n",
      "[OVERALL] N=1072\n",
      "  Acc    : 0.7966\n",
      "  AUROC  : 0.9680\n",
      "  AUPRC  : 0.9674\n",
      "  F1     : 0.7846\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, precision_recall_curve, auc, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "#           PATHS\n",
    "# =========================\n",
    "DJI_PATH     = r\"/home/destrox-907/Husnian_FYP/Dataset/Validation Dataset/DJI MAVIC 2\"\n",
    "PHANTOM_PATH = r\"/home/destrox-907/Husnian_FYP/Dataset/Validation Dataset/Phantom\"\n",
    "NOISE_PATH   = r\"/home/destrox-907/Husnian_FYP/Dataset/Validation Dataset/Acoustic Print GR Noise Audio_MFCC\"\n",
    "\n",
    "MODEL_THRESHOLDS = {\n",
    "    \"/home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_orignal.keras\": 0.50,\n",
    "    \"/home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_data_01.keras\": 0.35,\n",
    "    \"/home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_data_02.keras\": 0.35,\n",
    "    \"/home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_smoothing_AdamW.keras\": 0.40,\n",
    "    \"/home/destrox-907/Husnian_FYP/AI_Code Files/Testing Models/drone_resnet_SE_Aug.keras\": 0.30,\n",
    "}\n",
    "\n",
    "INPUT_SHAPE = (13, 40, 1)\n",
    "BATCH_SIZE  = 1024  # adjust if GPU RAM is tight\n",
    "\n",
    "# =========================\n",
    "#     DATA LOADING\n",
    "# =========================\n",
    "def collect_npy_paths(root_dir):\n",
    "    paths = []\n",
    "    for r, _, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".npy\"):\n",
    "                paths.append(os.path.join(r, f))\n",
    "    return sorted(paths)\n",
    "\n",
    "def load_all_paths_and_labels():\n",
    "    dji_paths     = collect_npy_paths(DJI_PATH)\n",
    "    phantom_paths = collect_npy_paths(PHANTOM_PATH)\n",
    "    noise_paths   = collect_npy_paths(NOISE_PATH)\n",
    "\n",
    "    # labels: DJI + PHANTOM are drone (1); NOISE is no-drone (0)\n",
    "    all_paths  = np.array(dji_paths + phantom_paths + noise_paths)\n",
    "    all_labels = np.array([1]*len(dji_paths) + [1]*len(phantom_paths) + [0]*len(noise_paths), dtype=np.int32)\n",
    "\n",
    "    print(f\"[INFO] DJI     : {len(dji_paths)} files (drone)\")\n",
    "    print(f\"[INFO] PHANTOM : {len(phantom_paths)} files (drone)\")\n",
    "    print(f\"[INFO] NOISE   : {len(noise_paths)} files (no-drone)\")\n",
    "    print(f\"[INFO] TOTAL   : {len(all_paths)} files\")\n",
    "\n",
    "    return all_paths, all_labels\n",
    "\n",
    "def npy_loader(path):\n",
    "    p = path.decode(\"utf-8\")\n",
    "    try:\n",
    "        arr = np.load(p)\n",
    "        arr = np.array(arr, dtype=\"float32\")\n",
    "        arr = np.reshape(arr, INPUT_SHAPE)  # enforce (13,40,1)\n",
    "        return arr\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to load {p}: {e}\")\n",
    "        return np.zeros(INPUT_SHAPE, dtype=\"float32\")\n",
    "\n",
    "def tf_load(path, label):\n",
    "    x = tf.numpy_function(npy_loader, [path], Tout=tf.float32)\n",
    "    x = tf.ensure_shape(x, INPUT_SHAPE)\n",
    "    y = tf.one_hot(label, 2)  # not used for loss; just to keep mapping simple\n",
    "    return x, y\n",
    "\n",
    "def make_dataset(all_paths, all_labels, batch=BATCH_SIZE):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((all_paths, all_labels))\n",
    "    ds = ds.map(tf_load, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# =========================\n",
    "#   CONFUSION MATRIX PLOT\n",
    "# =========================\n",
    "def plot_and_save_cm(y_true, y_pred, title, out_png):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Drone (0)\", \"Drone (1)\"])\n",
    "    fig, ax = plt.subplots(figsize=(5.2, 4.5), dpi=140)\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format=\"d\", ax=ax, colorbar=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png)\n",
    "    plt.close(fig)\n",
    "    print(f\"[SAVED] {out_png}\")\n",
    "    return cm\n",
    "\n",
    "# =========================\n",
    "#            RUN\n",
    "# =========================\n",
    "all_paths, all_labels = load_all_paths_and_labels()\n",
    "ds_all = make_dataset(all_paths, all_labels)\n",
    "\n",
    "for model_path, thr in MODEL_THRESHOLDS.items():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Evaluating model: {model_path}  (threshold={thr})\")\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not load model '{model_path}': {e}\")\n",
    "        continue\n",
    "\n",
    "    # Predict p(drone) over the entire combined set\n",
    "    probs = model.predict(ds_all, verbose=1)[:, 1]\n",
    "    y_true = all_labels.astype(int)\n",
    "    y_pred = (probs >= thr).astype(int)\n",
    "\n",
    "    # Metrics (for reference in console)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    auroc = roc_auc_score(y_true, probs) if len(np.unique(y_true)) > 1 else float(\"nan\")\n",
    "    prec, rec, th = precision_recall_curve(y_true, probs)\n",
    "    auprc = auc(rec, prec)\n",
    "    f1   = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"[OVERALL] N={len(y_true)}\")\n",
    "    print(f\"  Acc    : {acc:.4f}\")\n",
    "    print(f\"  AUROC  : {auroc:.4f}\")\n",
    "    print(f\"  AUPRC  : {auprc:.4f}\")\n",
    "    print(f\"  F1     : {f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix image\n",
    "    safe_name = os.path.splitext(os.path.basename(model_path))[0]\n",
    "    png_name  = f\"cm_{safe_name}.png\"\n",
    "    cm = plot_and_save_cm(y_true, y_pred, f\"Confusion Matrix: {safe_name} (thr={thr})\", png_name)\n",
    "    print(\"  CM rows=true [No-Drone(0), Drone(1)]  cols=predicted [0,1]:\")\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bad49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
