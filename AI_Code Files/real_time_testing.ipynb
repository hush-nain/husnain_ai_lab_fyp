{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f49ffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sounddevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqueue\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msounddevice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sounddevice'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "\n",
    "# =========================\n",
    "#           SETTINGS\n",
    "# =========================\n",
    "MODEL_PATH        = r\"/path/to/drone_resnet_final_form.keras\"  # <-- change\n",
    "TARGET_SR         = 16000\n",
    "WIN_SECONDS       = 1.0\n",
    "OVERLAP_SECONDS   = 0.3\n",
    "STEP_SECONDS      = WIN_SECONDS - OVERLAP_SECONDS  # 0.7 s\n",
    "\n",
    "# MFCC config (13x40 from 1 s @ 16 kHz)\n",
    "N_MFCC            = 13\n",
    "FRAMES_PER_SEC    = 40\n",
    "HOP_LENGTH        = TARGET_SR // FRAMES_PER_SEC   # 16000/40 = 400\n",
    "WIN_LENGTH        = 400\n",
    "N_FFT             = 1024\n",
    "\n",
    "# Classification output index and threshold\n",
    "DRONE_CLASS_INDEX = 1      # set to 0 if your softmax order is [drone, no_drone]\n",
    "PRINT_THRESHOLD   = 0.50\n",
    "\n",
    "# ====== MIC CALIBRATION (apply to audio BEFORE MFCC) ======\n",
    "# From your MATLAB reference:\n",
    "# Mul_fac = ((10^6.1925)/10^0.0475)*(20e-6)\n",
    "MUL_FAC = ((10.0**6.1925) / (10.0**0.0475)) * (20e-6)\n",
    "APPLY_CALIBRATION = True   # keep True to feed calibrated pressure into MFCC\n",
    "# ==========================================================\n",
    "\n",
    "SAVE_MFCC_NPY     = False\n",
    "SAVE_DIR          = \"./realtime_mfcc\"\n",
    "\n",
    "# =========================\n",
    "#     DEVICE SELECTION\n",
    "# =========================\n",
    "def find_umik_index():\n",
    "    \"\"\"Return input device index for UMIK-1, or None if not found.\"\"\"\n",
    "    try:\n",
    "        for i, d in enumerate(sd.query_devices()):\n",
    "            if d.get(\"max_input_channels\", 0) > 0 and \"umik\" in d.get(\"name\",\"\").lower():\n",
    "                return i\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "#   FEATURE EXTRACTION\n",
    "# =========================\n",
    "def mfcc_13x40(signal_16k):\n",
    "    \"\"\"signal_16k: 1-D float32 @16kHz. Returns (13,40,1).\"\"\"\n",
    "    y = np.asarray(signal_16k, dtype=np.float32).flatten()\n",
    "\n",
    "    # exact 1.0 s @ 16k samples\n",
    "    if y.size < TARGET_SR:\n",
    "        y = np.pad(y, (0, TARGET_SR - y.size), mode=\"constant\")\n",
    "    elif y.size > TARGET_SR:\n",
    "        y = y[:TARGET_SR]\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=TARGET_SR, n_mfcc=N_MFCC,\n",
    "        n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH, center=False\n",
    "    )  # (13, ~40)\n",
    "\n",
    "    if mfcc.shape[1] < FRAMES_PER_SEC:\n",
    "        mfcc = np.pad(mfcc, ((0,0),(0,FRAMES_PER_SEC - mfcc.shape[1])), mode=\"constant\")\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FRAMES_PER_SEC]\n",
    "\n",
    "    return mfcc[..., np.newaxis].astype(np.float32)  # (13,40,1)\n",
    "\n",
    "# =========================\n",
    "#        MAIN LOOP\n",
    "# =========================\n",
    "def main():\n",
    "    # 1) Require UMIK-1\n",
    "    device_index = find_umik_index()\n",
    "    if device_index is None:\n",
    "        print(\"[ERROR] UMIK-1 microphone not found. Connect it and try again.\")\n",
    "        sys.exit(1)\n",
    "    print(f\"[INFO] UMIK-1 found at input device index: {device_index}\")\n",
    "\n",
    "    # 2) Load model\n",
    "    print(f\"[INFO] Loading model: {MODEL_PATH}\")\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "    # 3) Open stream (request 16k; we still enforce 16k after capture)\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def audio_cb(indata, frames, time_info, status):\n",
    "        if status:\n",
    "            print(f\"[AUDIO WARN] {status}\", flush=True)\n",
    "        q.put(indata.copy())\n",
    "\n",
    "    requested_sr = TARGET_SR\n",
    "    print(f\"[INFO] Opening stream (requested_sr={requested_sr}) â€¦\")\n",
    "    with sd.InputStream(\n",
    "        samplerate=requested_sr,\n",
    "        channels=1,\n",
    "        dtype=\"float32\",\n",
    "        callback=audio_cb,\n",
    "        device=device_index,\n",
    "        blocksize=0\n",
    "    ) as stream:\n",
    "        actual_sr = int(stream.samplerate)\n",
    "        print(f\"[INFO] Stream active. ACTUAL device rate = {actual_sr} Hz\")\n",
    "\n",
    "        # accumulate raw audio at 'actual_sr', then resample to 16k\n",
    "        step_len_actual = int(round(STEP_SECONDS * actual_sr))    # ~0.7 s\n",
    "        pending = np.zeros(0, dtype=np.float32)\n",
    "\n",
    "        # Overlap in 16k domain\n",
    "        overlap_len_16k = int(round(OVERLAP_SECONDS * TARGET_SR))  # 4800 samples\n",
    "        tail_16k = np.zeros(overlap_len_16k, dtype=np.float32)\n",
    "\n",
    "        if SAVE_MFCC_NPY:\n",
    "            os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "        print(\"[INFO] Press Ctrl+C to stop.\\n\")\n",
    "        counter = 0\n",
    "        while True:\n",
    "            try:\n",
    "                # Accumulate until we have one step (~0.7 s at actual_sr)\n",
    "                while pending.size < step_len_actual:\n",
    "                    fresh = q.get()[:, 0]  # mono float32\n",
    "                    pending = np.concatenate([pending, fresh], axis=0)\n",
    "\n",
    "                fresh_step_actual = pending[:step_len_actual]\n",
    "                pending = pending[step_len_actual:]\n",
    "\n",
    "                # Resample that step to 16 kHz\n",
    "                fresh_step_16k = librosa.resample(\n",
    "                    y=fresh_step_actual, orig_sr=actual_sr, target_sr=TARGET_SR, res_type=\"kaiser_best\"\n",
    "                )\n",
    "\n",
    "                # Compose 1.0 s @ 16 kHz: [last 0.3 s] + [new 0.7 s]\n",
    "                window_16k = np.concatenate([tail_16k, fresh_step_16k], axis=0)\n",
    "\n",
    "                # Enforce exact 1.0 s length\n",
    "                if window_16k.size < TARGET_SR:\n",
    "                    window_16k = np.pad(window_16k, (0, TARGET_SR - window_16k.size), mode=\"constant\")\n",
    "                elif window_16k.size > TARGET_SR:\n",
    "                    window_16k = window_16k[-TARGET_SR:]\n",
    "\n",
    "                # Update tail: last 0.3 s\n",
    "                tail_16k = window_16k[-overlap_len_16k:].copy()\n",
    "\n",
    "                # --- Calibration applied to audio before MFCC ---\n",
    "                signal_for_mfcc = window_16k * MUL_FAC if APPLY_CALIBRATION else window_16k\n",
    "\n",
    "                # MFCC (13x40x1)\n",
    "                tile = mfcc_13x40(signal_for_mfcc)\n",
    "\n",
    "                if SAVE_MFCC_NPY:\n",
    "                    np.save(os.path.join(SAVE_DIR, f\"mfcc_{int(time.time())}_{counter:06d}.npy\"), tile)\n",
    "\n",
    "                # Inference\n",
    "                probs = model.predict(tile[np.newaxis, ...], verbose=0)[0]\n",
    "                p_drone = float(probs[DRONE_CLASS_INDEX])\n",
    "\n",
    "                label = \"DRONE\" if p_drone >= PRINT_THRESHOLD else \"NO-DRONE\"\n",
    "                ts = time.strftime(\"%H:%M:%S\")\n",
    "                print(f\"[{ts}] p(drone)={p_drone:0.3f}  -> {label}\")\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n[INFO] Stopped by user.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {e}\", flush=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
